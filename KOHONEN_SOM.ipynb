{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from accuracy_calc import *\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question_id</th>\n",
       "      <th>correctly_answered</th>\n",
       "      <th>incorrectly_answered</th>\n",
       "      <th>not_answered</th>\n",
       "      <th>avg_marks_correct</th>\n",
       "      <th>avg_marks_incorrect</th>\n",
       "      <th>avg_marks_na</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>perc_corr</th>\n",
       "      <th>perc_na</th>\n",
       "      <th>perc_incorr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>91</td>\n",
       "      <td>34</td>\n",
       "      <td>30.4167</td>\n",
       "      <td>17.7253</td>\n",
       "      <td>24.6855</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.278695</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>88</td>\n",
       "      <td>53</td>\n",
       "      <td>29.8246</td>\n",
       "      <td>15.0341</td>\n",
       "      <td>19.9795</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>132</td>\n",
       "      <td>48</td>\n",
       "      <td>31.1045</td>\n",
       "      <td>21.3409</td>\n",
       "      <td>26.5354</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.131860</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>34.8288</td>\n",
       "      <td>15.3692</td>\n",
       "      <td>22.0449</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.340585</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>31.6951</td>\n",
       "      <td>21.3093</td>\n",
       "      <td>27.0053</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  question_id  correctly_answered  incorrectly_answered  \\\n",
       "0           0            1                 144                    91   \n",
       "1           1            2                 114                    88   \n",
       "2           2            3                  67                   132   \n",
       "3           3            4                 146                    65   \n",
       "4           4            5                  82                    97   \n",
       "\n",
       "   not_answered  avg_marks_correct  avg_marks_incorrect  avg_marks_na  \\\n",
       "0            34            30.4167              17.7253       24.6855   \n",
       "1            53            29.8246              15.0341       19.9795   \n",
       "2            48            31.1045              21.3409       26.5354   \n",
       "3            54            34.8288              15.3692       22.0449   \n",
       "4            63            31.6951              21.3093       27.0053   \n",
       "\n",
       "         f1        f2  perc_corr  perc_na  perc_incorr  \n",
       "0  0.007733  0.278695         25        6            1  \n",
       "1  0.006053  0.208200         13        0            2  \n",
       "2  0.003645  0.131860         11       11           12  \n",
       "3  0.008500  0.340585         41        6            2  \n",
       "4  0.004511  0.178583         21       18            8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_vals = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39940828, 0.2724359 , 0.29824561, 0.56506579, 0.51733735,\n",
       "       0.59946264, 0.42556471, 0.45540564, 0.43859649, 0.15384615,\n",
       "       0.02702703])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = MinMaxScaler()\n",
    "data = ss.fit_transform(np.array(df[col_vals[1:12]]))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "features = len(data[0])\n",
    "total_data = len(data)\n",
    "W = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(total_data):\n",
    "    '''\n",
    "    function for initialize random values in the weight vectors for the neural network to be used.\n",
    "    uses the no of features to initialize a vector.\n",
    "    '''\n",
    "    y = np.random.random()*(2.0/np.sqrt(total_data))\n",
    "    return 0.5 - (1/np.sqrt(total_data)) + y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the above function to initialize the weight vectors\n",
    "'''\n",
    "for i in range(n_clusters):\n",
    "    W.append(list())\n",
    "    for j in range(features):\n",
    "        W[i].append(get_weights() * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2555237560289629,\n",
       "  0.25223635191258925,\n",
       "  0.24102473695737708,\n",
       "  0.25515116707828167,\n",
       "  0.24229903814470533,\n",
       "  0.25200621034550197,\n",
       "  0.23978730277346097,\n",
       "  0.25867184906231566,\n",
       "  0.2409201305398317,\n",
       "  0.2519038336141455,\n",
       "  0.2386874120347491],\n",
       " [0.2508946456869702,\n",
       "  0.2458997733876654,\n",
       "  0.251159332793222,\n",
       "  0.2582695663211468,\n",
       "  0.2508801293476367,\n",
       "  0.2563892370781587,\n",
       "  0.25129078452283177,\n",
       "  0.2463051314720393,\n",
       "  0.24775153231964853,\n",
       "  0.24988826082485552,\n",
       "  0.23875657652444127],\n",
       " [0.25147468570776016,\n",
       "  0.2400584962302346,\n",
       "  0.2510743156167749,\n",
       "  0.25165339152813393,\n",
       "  0.2601248278056805,\n",
       "  0.2495500415433837,\n",
       "  0.2571481360053348,\n",
       "  0.24766253608215752,\n",
       "  0.2508060114433547,\n",
       "  0.2455484560101217,\n",
       "  0.25132065140483345]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_distance(w,x):\n",
    "    '''\n",
    "    function for computing the distance between the x(data) and w(Weight) vector\n",
    "    takes in two arguments \n",
    "    w: weights\n",
    "    x: features\n",
    "    '''\n",
    "    distance=0\n",
    "    for i in range(len(w)):\n",
    "        distance = distance + (w[i] - x[i])*(w[i] - x[i])\n",
    "    distance = np.sqrt(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_to_x(W,x):\n",
    "    '''\n",
    "    function to calculate the closest x vectors to the w vectors\n",
    "    takes in two arguments\n",
    "    w: weights\n",
    "    x: features\n",
    "    '''\n",
    "    \n",
    "    w = W[0]\n",
    "    dist = compute_distance(w,x)\n",
    "    i = 0\n",
    "    i_n = i\n",
    "    for w_ in W:\n",
    "        if compute_distance(w_,x)<dist:\n",
    "            dist = compute_distance(w_, x)\n",
    "            w = w_\n",
    "            i_n = i\n",
    "        i = i + 1\n",
    "    return (w,i_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After receiving an input vector x, the winning neuron modifies the value of its previous vector w in a loop according to the formula *wn = wn+λ (xn-wn)*, where λ is a coefficient, which we reduce by Δλ in each iteration of the loop unless λ>0. We do this for each x in our training set. We can pick input vectors randomly or in a specific order. In this loop, λ and Δλ are our parameters, which we define and can modify.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(data):\n",
    "    W=[]\n",
    "    n_clusters = 3\n",
    "    features = len(data[0])\n",
    "    total_data = len(data)\n",
    "    for i in range(n_clusters):\n",
    "        W.append(list())\n",
    "        for j in range(features):\n",
    "            W[i].append(get_weights(total_data) * 0.5)\n",
    "    la = 0.3   # λ coefficient\n",
    "    dla = 0.05  # Δλ\n",
    "    '''\n",
    "    This code applies the training process defined above for every data point given in the dataset.\n",
    "    We run a loop till la is equal to 0. In that we take 10 iterations and find closest datapoint ot the neuron and then\n",
    "    updates the value of the wn as in the above equation.\n",
    "    '''\n",
    "    while la >= 0:\n",
    "        for k in range(10):\n",
    "            for x in data:\n",
    "                wm = find_closest_to_x(W, x)[0]\n",
    "                for i in range(len(wm)):\n",
    "                    wm[i] = wm[i] + la * (x[i] - wm[i]) \n",
    "        la = la - dla\n",
    "    prediction=[]\n",
    "    for x in data:\n",
    "        i_n = find_closest_to_x(W,x)[1]\n",
    "        prediction.append(i_n)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing in the original tags\n",
    "conn = sqlalchemy.create_engine(\"mysql+pymysql://anuj:Anuj@21101998@localhost/auto_tagging_data\")\n",
    "df = pd.read_sql(\"question_master\",conn)\n",
    "tags = list(df[\"pre_tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53  and the distribution is  651 hard  642 medium  507 easy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/Desktop/auto-tagging2.0/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(acc(np.array(tags),np.array(predictions)),\" and the distribution is \",predictions.count(2),\"hard \",predictions.count(1),\"medium \",predictions.count(0),\"easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
